{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bcd1a9-37de-401d-ac3f-da9b5105154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 703 ms\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from unstructured.partition.auto import partition\n",
    "import unstructured\n",
    "import pickle\n",
    "import os\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f31fbaf-ba9c-43ea-9c63-afe4396b9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_name(hash_id):\n",
    "    resources = json.load(open('./resources/res.json'))\n",
    "    pdfname = list(filter(lambda x:x['hash'] == hash_id,resources))[0]['filename']\n",
    "    return \"./resources/\"+pdfname\n",
    "def load_pdf(hash, cache=True):\n",
    "    pklfn = './resources/'+hash+\".pkl\"\n",
    "    if os.path.isfile(pklfn) and cache:\n",
    "        pages = pickle.load(open(pklfn, 'rb'))\n",
    "        return pages\n",
    "    fname = load_pdf_name(hash)\n",
    "    elements = partition(fname)\n",
    "    pages = list(range(elements[-1].metadata.page_number))\n",
    "\n",
    "    for el in elements:\n",
    "        if type(pages[el.metadata.page_number-1]) == int:\n",
    "            pages[el.metadata.page_number-1] = []\n",
    "        if type(el)==unstructured.documents.elements.Footer:\n",
    "            continue\n",
    "        if type(el)==unstructured.documents.elements.Header:\n",
    "            continue\n",
    "        pages[el.metadata.page_number-1].append(el)\n",
    "    pickle.dump(pages,open(pklfn, 'wb'))\n",
    "    return pages\n",
    "def prep_documents_set(pdf_pages):\n",
    "    docs = []\n",
    "    for p in pdf_pages:\n",
    "        str = \"\"\n",
    "        # print(type(p))\n",
    "        for el in p:\n",
    "            str += el.text+\"\\n\"\n",
    "        docs.append(str)\n",
    "    return docs\n",
    "def docs_overlap(_docs):\n",
    "    docs = _docs.copy()\n",
    "    maxl = len(docs)\n",
    "    splitter_char = \". \"\n",
    "    overlap_num_sentences = 3\n",
    "    for i, doc in enumerate(docs):\n",
    "        if i<1:\n",
    "            continue\n",
    "        prechunk = _docs[i-1].split(splitter_char)[-overlap_num_sentences:]\n",
    "        # if i == 9: print(prechunk)\n",
    "        docs[i] = splitter_char.join(prechunk) + docs[i]\n",
    "        if i>=maxl-1:\n",
    "            continue\n",
    "        pstchunk = _docs[i+1].split(splitter_char)[:overlap_num_sentences]\n",
    "        docs[i] = docs[i] + splitter_char.join(pstchunk)\n",
    "    return docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9705ead6-fa06-414d-8802-f5acb2bb9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pages = load_pdf(\"0e3ad6ccde4c4675ac0fea7c6ee35bc7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d31ed968-bffc-4487-aa4f-754fb63cd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(pages,open('./resources/857irwueifdkjwo9eruj2iroeakdfm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b918f7d-5b75-4c6c-bc3f-51c69a50ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ijkl', 'mnop', 'qrst']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"abcd efgh ijkl mnop qrst\".split(' ')[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9390f20a-7f60-41d7-ba4d-68387cc66d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Title: RAG Document Q&A Chatbot Development\n",
      "1. Introduction:\n",
      "The purpose of this document is to outline the requirements for developing a RAG (Retrieval-Augmented Generation) Q&A chatbot with the capability to load and process data from various file formats, store embeddings in a local vector database, and provide a frontend UI for user interaction.\n",
      "2. Project Overview:\n",
      "The project involves the development of a RAG Q&A chatbot leveraging state-of-the-art techniques in natural language processing (NLP), machine learning and Generative AI. The Q&A chatbot will be capable of understanding user queries, retrieving relevant information from pre-loaded data files, and presenting the information in a user-friendly manner through a Streamlit-based frontend UI.\n",
      "3. Functional Requirements:\n",
      "Data Loading (one time):\n",
      "The chatbot should be able to load data from various file formats including PDF, WORD, JSON, CSV, Key- value pair, EXCEL, etc. Upon loading, the data should be processed to extract relevant text information for further processing.\n",
      "Embedding Generation:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = prep_documents_set(pages)\n",
    "ov = docs_overlap(docs)\n",
    "print(ov[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a726e408-d47b-4b99-a70d-708fb78b2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18343708-a1b3-4ad1-8d8b-26f057e128ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary=[\"The attacker used duct tape to affix Čarek's hand, holding the gun, to his head and then killed him\", 'The police suspect a connection between the murder and a man with a bullet wound who appeared at the hospital', 'All three witnesses who could identify the man with the bullet wound were killed with an axe', 'The police believe the killer was a trained terrorist, not linked to serial killers like Kottmann', \"Kottmann's last words hint at completing a mission, raising questions about his involvement\", 'The Dorn series is popular among teens but criticized for its extreme violence and sexual content', 'Personal theory suggests the man with the injured arm who checked into the hospital was the killer'] precontext=\"The page discusses the aftermath of Čarek's murder, with the police investigating potential leads and connections between different individuals. It also delves into the controversial nature of the Dorn series and presents a personal theory regarding the identity of the killer.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from typing import List\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "\n",
    "class PageSummary(BaseModel):\n",
    "    summary:List[str] = Field(description=\"Summary of given page content as a list of string\")\n",
    "    precontext: str = Field(description=\"General Summary of the the page to use as context to provide summary for future pdfs. Generate this field such that the old precontext is preserved, but still, the context of this page dominates, so that the context is clearer for next page\")\n",
    "    pass\n",
    "parser = PydanticOutputParser(pydantic_object=PageSummary)\n",
    "\n",
    "\n",
    "precontext_template = PromptTemplate(\n",
    "    template=\"\"\"You're a content summarizer bot. From a book/pdf, Summarize the following one page content in bullet points: \n",
    "    \n",
    "    {content}\n",
    "\n",
    "    The context of the pdf till now is following, just to have an idea of what above content might mean:\n",
    "    {precontext}\n",
    "\n",
    "    Output Format Instruction:\n",
    "    {format_instructions}\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"content\", \"precontext\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"You're a content summarizer bot. From a book/pdf, Summarize the following one page content in bullet points: \n",
    "    \n",
    "    {content}\n",
    "\n",
    "    Output Format Instruction:\n",
    "    {format_instructions}\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables=[\"content\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "default_summarize_chain = template | model | parser\n",
    "\n",
    "precontext_summarize_chain = precontext_template | model | parser\n",
    "\n",
    "\n",
    "def summarize(txt, gen_summary=\"\"):\n",
    "    if gen_summary == \"\":\n",
    "        return default_summarize_chain.invoke({\"content\":txt})\n",
    "    return precontext_summarize_chain.invoke({\"content\":txt, \"precontext\":gen_summary})\n",
    "\n",
    "inpu = \"\"\"The attacker used duct tape to affix Čarek's hand, holding the gun, to his head. Now all he had to do was pull the trigger, and after confirming Čarek's death, remove the tape and any signs of a third party from the room. We don't know who the attacker\n",
    "was, but he was certainly a professional.\n",
    "The Salzburg police finally set their sights on the man who appeared at St. Ursula\n",
    "Clinic at 2:00 AM the day after the murder. It had now been two weeks since Čarek's murder — but the only three people who could possibly identify this man had been killed with an axe...\n",
    "The police believe there is a connection between the Čarek murder and the man with\n",
    "the bullet wound who appeared at the hospital, but they do not recognize a link between this man and Kottmann. The fact that all three witnesses were murdered was an unfortunate coincidence. Their line of reasoning is this: the man who killed Čarek was a trained terrorist, and those types of people never have ties to serial killers. Kottmann was the type who acted on his desires and impulses, and not the kind of person who would commit murder at the request of another and commit suicide afterward, to seal the case — which makes sense.\n",
    "But they have no answer for Kottmann's last words: \"One, two, three... My mission is\n",
    "complete.\"\n",
    "An illustration from Dorn in the Darkness. With its wavering message that shifts between good and evil, the Dorn series has a fanatical teen readership, but due to its extreme violence and sexual material, is derisively called \"the most enticing kind of pulp literature\" by critics.\n",
    "My own personal theory goes like this. The man who checked in to the hospital with the injured arm was the man who killed Čarek. He hoped that the hospital staff would not report his presence to the police, but he had a plan in case they did\"\"\"\n",
    "\n",
    "outp = summarize(inpu)\n",
    "\n",
    "print(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7e3726e-0082-443f-bab0-5fde835cb1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2fb30e1-31ba-454f-882d-84138166965b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
